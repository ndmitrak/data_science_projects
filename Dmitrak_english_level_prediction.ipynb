{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a0b7065",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Откроем-и-изучим-данные\" data-toc-modified-id=\"Откроем-и-изучим-данные-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Откроем и изучим данные</a></span><ul class=\"toc-item\"><li><span><a href=\"#Откроем-данные\" data-toc-modified-id=\"Откроем-данные-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Откроем данные</a></span></li><li><span><a href=\"#Изучим-данные\" data-toc-modified-id=\"Изучим-данные-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Изучим данные</a></span></li></ul></li><li><span><a href=\"#Проведем-предобработку-данных\" data-toc-modified-id=\"Проведем-предобработку-данных-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Проведем предобработку данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Проведем-предобработку-df_xls\" data-toc-modified-id=\"Проведем-предобработку-df_xls-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Проведем предобработку df_xls</a></span></li><li><span><a href=\"#Проведем-предобраобтку-df_subtitles\" data-toc-modified-id=\"Проведем-предобраобтку-df_subtitles-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Проведем предобраобтку df_subtitles</a></span></li><li><span><a href=\"#Проведем-предобраобтку-df_dictionaries\" data-toc-modified-id=\"Проведем-предобраобтку-df_dictionaries-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Проведем предобраобтку df_dictionaries</a></span></li><li><span><a href=\"#Объединим-таблицы\" data-toc-modified-id=\"Объединим-таблицы-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Объединим таблицы</a></span></li></ul></li><li><span><a href=\"#Обучим-модель\" data-toc-modified-id=\"Обучим-модель-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучим модель</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e933b",
   "metadata": {},
   "source": [
    "# Мастерская 2 #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c1907",
   "metadata": {},
   "source": [
    "Проект выполняется в рамках Мастерской Яндекс Практикума.\n",
    "Выполнила: Дмитрак Наталья @n_dmitrak\n",
    "\n",
    "**Цель** — создание системы для автоматического определения уровня сложности англоязычных фильмов.<br>\n",
    "\n",
    "\n",
    "**Использованные данные:**<br>\n",
    "    \n",
    "-субтитры к фильмам<br>\n",
    "-словари для определения уровня знания английского языка<br> \n",
    "\n",
    "**Задача**<br>\n",
    "Разработка ML-решения для автоматического определения уровня сложности англоязычных фильмов.<br>    \n",
    "Важно выбрать фильм, который подходит студенту по уровню сложности, т.е. студент должен понимать 50-70% диалогов.<br>\n",
    "Необходимо обучить языковую модель, разработать для неё веб-интерфейс и создать микросервис.   \n",
    "    \n",
    "**Ход реализации**<br>\n",
    "1. Загрузим данные<br>\n",
    "2. Проведем предварительную обработку данных/EDA<br>  \n",
    "3. Обучим модель\n",
    "4. Оценим качество получившейся модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30362e4d",
   "metadata": {},
   "source": [
    "## Откроем и изучим данные ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b4d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим необходимые библиотеки \n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pdfplumber\n",
    "import pysrt\n",
    "import chardet\n",
    "import sweetviz as sv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d84ce1",
   "metadata": {},
   "source": [
    "### Откроем данные ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db47321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таблица xls загружена с компьютера\n",
      "Таблица xls:\n",
      "   id                             Movie   Level\n",
      "0   0         10_Cloverfield_lane(2016)      B1\n",
      "1   1  10_things_I_hate_about_you(1999)      B1\n",
      "2   2              A_knights_tale(2001)      B2\n",
      "3   3              A_star_is_born(2018)      B2\n",
      "4   4                     Aladdin(1992)  A2/A2+\n"
     ]
    }
   ],
   "source": [
    "# загрузим таблицу \n",
    "\n",
    "xls_file_path = '/Users/nata/Desktop/Мастерская-2/English_level/English_scores/movies_labels.xlsx'\n",
    "try:\n",
    "    df_xls = pd.read_excel(xls_file_path)\n",
    "    print(\"Таблица xls загружена с компьютера\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Файл xls не найден на компьютере\")\n",
    "    # если загрузка с компьютера не удалась, загрузим таблицу xls из интернета\n",
    "    xls_url = 'https://docviewer.yandex.ru/view/786181067/?*=exuH9EgdsE1zPMskziJKflErhIF7InVybCI6InlhLWRpc2stcHVibGljOi8vSjlIK09zQm9ralMwblM2L1ZvUVNURDFHMGg4YTlTUitzMWg1bDdSU1RkQ2xwYnhtZnRwd01EdGRXRFBJcjJORnEvSjZicG1SeU9Kb25UM1ZvWG5EYWc9PTovRW5nbGlzaF9zY29yZXMuemlwIiwidGl0bGUiOiJFbmdsaXNoX3Njb3Jlcy56aXAiLCJub2lmcmFtZSI6ZmFsc2UsInVpZCI6Ijc4NjE4MTA2NyIsInRzIjoxNjg4ODM1MjEzNDE1LCJ5dSI6IjEzNTI1MzgyMjE2Nzg0MzUxOTgifQ%3D%3D'\n",
    "    try:\n",
    "        response = requests.get(xls_url)\n",
    "        df_xls = pd.read_excel(BytesIO(response.content))\n",
    "        print(\"Таблица xls загружена из интернета\")\n",
    "    except Exception as e:\n",
    "        print(\"Ошибка при загрузке таблицы xls:\", e)\n",
    "\n",
    "# выведем загруженную таблицу\n",
    "print(\"Таблица xls:\")\n",
    "print(df_xls.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c6b763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при загрузке субтитров: name 'requests' is not defined\n",
      "Ошибка при загрузке субтитров: name 'requests' is not defined\n",
      "Таблица субтитров:\n",
      "                                               movie  \\\n",
      "0            Crown, The S01E01 - Wolferton Splash.en   \n",
      "1                            Suits.Episode 1- Denial   \n",
      "2  Crazy4TV.com - Suits.S06E06.720p.BluRay.x265.H...   \n",
      "3                      Suits.S02E08.HDTV.x264-EVOLVE   \n",
      "4  Virgin.River.S01E07.INTERNAL.720p.WEB.x264-STRiFE   \n",
      "\n",
      "                                           subtitles  \n",
      "0  1\\n00:00:59,400 --> 00:01:03,960\\nIn seeking h...  \n",
      "1  1\\n00:00:07,298 --> 00:00:09,332\\nYou're the m...  \n",
      "2  1\\n00:00:00,877 --> 00:00:02,337\\n(HARVEY READ...  \n",
      "3  1\\n00:00:05,640 --> 00:00:07,641\\n[Car horn bl...  \n",
      "4  1\\n00:00:10,468 --> 00:00:13,178\\nAre you sure...  \n"
     ]
    }
   ],
   "source": [
    "# загрузим субтитры \n",
    "\n",
    "subtitles_list = []\n",
    "\n",
    "# загрузим субтитры из локальных файлов\n",
    "for dirpath, dirs, files in os.walk('/Users/nata/Desktop/Мастерская-2'):\n",
    "    for file in files:\n",
    "        if file.endswith('.srt'):\n",
    "            # определим кодировку файла\n",
    "            rawdata = open(os.path.join(dirpath, file), 'rb').read()\n",
    "            result = chardet.detect(rawdata)\n",
    "            encoding = result['encoding']\n",
    "            \n",
    "            # откроем файл с обнаруженной кодировкой\n",
    "            with open(os.path.join(dirpath, file), 'r', encoding=encoding, errors='ignore') as f:\n",
    "                text = f.read()\n",
    "                movie_name = file[:-4]  # извлечем название фильма из имени файла\n",
    "                subtitles_list.append((movie_name, text))\n",
    "\n",
    "# загрузим субтитры из интернета\n",
    "urls = [\n",
    "    'https://docviewer.yandex.ru/view/786181067/?*=Uc72FZjr7UQ%2FQx1Vjre7%2B1U4JBh7InVybCI6InlhLWRpc2stcHVibGljOi8vSjlIK09zQm9ralMwblM2L1ZvUVNURDFHMGg4YTlTUitzMWg1bDdSU1RkQ2xwYnhtZnRwd01EdGRXRFBJcjJORnEvSjZicG1SeU9Kb25UM1ZvWG5EYWc9PTovRW5nbGlzaF9zY29yZXMuemlwIiwidGl0bGUiOiJFbmdsaXNoX3Njb3Jlcy56aXAiLCJub2lmcmFtZSI6ZmFsc2UsInVpZCI6Ijc4NjE4MTA2NyIsInRzIjoxNjg4OTMyNDcxMjcxLCJ5dSI6IjEzNTI1MzgyMjE2Nzg0MzUxOTgifQ%3D%3D',\n",
    "    'https://disk.yandex.ru/d/CkmiSRnKba76sA'\n",
    "]\n",
    "\n",
    "for url in urls:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        df_temp = pd.read_csv(BytesIO(response.content), sep='\\t', header=None)\n",
    "        movie_name = df_temp.iloc[0, 0]\n",
    "        subtitles = df_temp.iloc[1:, 0].str.cat(sep='\\n')\n",
    "        subtitles_list.append((movie_name, subtitles))\n",
    "        print(f\"Субтитры загружены: {movie_name}\")\n",
    "    except Exception as e:\n",
    "        print(\"Ошибка при загрузке субтитров:\", e)\n",
    "\n",
    "# создадим DataFrame субтитров\n",
    "df_subtitles = pd.DataFrame(subtitles_list, columns=['movie', 'subtitles'])\n",
    "\n",
    "# напечатаем загруженную таблицу\n",
    "print(\"Таблица субтитров:\")\n",
    "print(df_subtitles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64b7c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при загрузке словаря: name 'requests' is not defined\n",
      "Таблица словарей:\n",
      "     word level\n",
      "0    bank    A1\n",
      "1     buy    A1\n",
      "2  course    A1\n",
      "3     bar    A1\n",
      "4      by    A1\n"
     ]
    }
   ],
   "source": [
    "# загрузим словари \n",
    "\n",
    "# создадим пустой DataFrame для хранения данных\n",
    "df_dictionaries = pd.DataFrame(columns=['word', 'level'])\n",
    "\n",
    "current_level = None\n",
    "\n",
    "# загрузим словари из локальных файлов\n",
    "for dict_file in os.listdir('/Users/nata/Desktop/Мастерская-2/English_level/Oxford_CEFR_level'):\n",
    "    if dict_file.endswith('.pdf'):\n",
    "        with pdfplumber.open(os.path.join('/Users/nata/Desktop/Мастерская-2/English_level/Oxford_CEFR_level', dict_file)) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text()\n",
    "                for line in text.split('\\n'):\n",
    "                    if line.strip():  # проверим, что строка не пустая\n",
    "                        line = line.split()  # разделим строку на слова\n",
    "                        if len(line) == 1 and line[0] in ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']:  # проверим, является ли это новым уровнем\n",
    "                            current_level = line[0]\n",
    "                        elif current_level is not None:\n",
    "                            for word in line:\n",
    "                                if word.isalpha():  # проверим, состоит ли слово только из букв\n",
    "                                    new_row = pd.DataFrame({'word': [word], 'level': [current_level]})\n",
    "                                    df_dictionaries = pd.concat([df_dictionaries, new_row], ignore_index=True)\n",
    "\n",
    "# загрузим словари из интернета\n",
    "urls = [\n",
    "    'https://docviewer.yandex.ru/view/786181067/?*=4L9A%2FdYJlUiDJaD0TeyudQgZZON7InVybCI6InlhLWRpc2stcHVibGljOi8vSjlIK09zQm9ralMwblM2L1ZvUVNURDFHMGg4YTlTUitzMWg1bDdSU1RkQ2xwYnhtZnRwd01EdGRXRFBJcjJORnEvSjZicG1SeU9Kb25UM1ZvWG5EYWc9PTovT3hmb3JkX0NFRlJfbGV2ZWwuemlwIiwidGl0bGUiOiJPeGZvcmRfQ0VGUl9sZXZlbC56aXAiLCJub2lmcmFtZSI6ZmFsc2UsInVpZCI6Ijc4NjE4MTA2NyIsInRzIjoxNjg4OTMyNjAwMzE2LCJ5dSI6IjEzNTI1MzgyMjE2Nzg0MzUxOTgifQ%3D%3D'\n",
    "]\n",
    "\n",
    "for url in urls:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        df_temp = pd.read_csv(BytesIO(response.content), sep='\\t', header=None)\n",
    "        df_temp.columns = ['word', 'level']\n",
    "        df_dictionaries = pd.concat([df_dictionaries, df_temp], ignore_index=True)\n",
    "        print(\"Словарь загружен\")\n",
    "    except Exception as e:\n",
    "        print(\"Ошибка при загрузке словаря:\", e)\n",
    "\n",
    "# напечатаем получившийся DataFrame\n",
    "print(\"Таблица словарей:\")\n",
    "print(df_dictionaries.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec7c443",
   "metadata": {},
   "source": [
    "### Изучим данные ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29524f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим функцию для получения информации о данных\n",
    "\n",
    "def get_data_info(data):\n",
    "    print(data)\n",
    "    print(\"Общая информация:\")\n",
    "    display(data.info())\n",
    "\n",
    "    print(\"Первые 5 строк:\")\n",
    "    display(data.head())\n",
    "\n",
    "    print(\"Количество уникальных значений в каждом столбце:\")\n",
    "    for column in data.columns:\n",
    "        if not isinstance(data[column].iloc[0], list):\n",
    "            print(f\"Столбец: {column}\")\n",
    "            print(f\"Количество уникальных значений: {data[column].nunique()}\")\n",
    "            print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b237df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим словарь с названиями датафреймов\n",
    "dfs = {'xls': df_xls, 'subtitles': df_subtitles, 'dictionaries': df_dictionaries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb99ab2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xls'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                             Movie   Level\n",
      "0      0         10_Cloverfield_lane(2016)      B1\n",
      "1      1  10_things_I_hate_about_you(1999)      B1\n",
      "2      2              A_knights_tale(2001)      B2\n",
      "3      3              A_star_is_born(2018)      B2\n",
      "4      4                     Aladdin(1992)  A2/A2+\n",
      "..   ...                               ...     ...\n",
      "236  236                     Matilda(2022)      C1\n",
      "237  237                      Bullet train      B1\n",
      "238  238            Thor: love and thunder      B2\n",
      "239  239                         Lightyear      B2\n",
      "240  240                        The Grinch      B1\n",
      "\n",
      "[241 rows x 3 columns]\n",
      "Общая информация:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 241 entries, 0 to 240\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      241 non-null    int64 \n",
      " 1   Movie   241 non-null    object\n",
      " 2   Level   241 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 5.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 5 строк:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2/A2+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                             Movie   Level\n",
       "0   0         10_Cloverfield_lane(2016)      B1\n",
       "1   1  10_things_I_hate_about_you(1999)      B1\n",
       "2   2              A_knights_tale(2001)      B2\n",
       "3   3              A_star_is_born(2018)      B2\n",
       "4   4                     Aladdin(1992)  A2/A2+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных значений в каждом столбце:\n",
      "Столбец: id\n",
      "Количество уникальных значений: 241\n",
      "--------------------\n",
      "Столбец: Movie\n",
      "Количество уникальных значений: 237\n",
      "--------------------\n",
      "Столбец: Level\n",
      "Количество уникальных значений: 7\n",
      "--------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'subtitles'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 movie  \\\n",
      "0              Crown, The S01E01 - Wolferton Splash.en   \n",
      "1                              Suits.Episode 1- Denial   \n",
      "2    Crazy4TV.com - Suits.S06E06.720p.BluRay.x265.H...   \n",
      "3                        Suits.S02E08.HDTV.x264-EVOLVE   \n",
      "4    Virgin.River.S01E07.INTERNAL.720p.WEB.x264-STRiFE   \n",
      "..                                                 ...   \n",
      "359                         The_greatest_showman(2017)   \n",
      "360                     Kubo_and_the_two_strings(2016)   \n",
      "361                                      Matilda(1996)   \n",
      "362                                          Her(2013)   \n",
      "363                                      Aladdin(1992)   \n",
      "\n",
      "                                             subtitles  \n",
      "0    1\\n00:00:59,400 --> 00:01:03,960\\nIn seeking h...  \n",
      "1    1\\n00:00:07,298 --> 00:00:09,332\\nYou're the m...  \n",
      "2    1\\n00:00:00,877 --> 00:00:02,337\\n(HARVEY READ...  \n",
      "3    1\\n00:00:05,640 --> 00:00:07,641\\n[Car horn bl...  \n",
      "4    1\\n00:00:10,468 --> 00:00:13,178\\nAre you sure...  \n",
      "..                                                 ...  \n",
      "359  1\\n00:00:09,877 --> 00:00:13,081\\n♪ Whoa ♪\\n\\n...  \n",
      "360  1\\n00:00:23,240 --> 00:00:26,403\\nIf you must ...  \n",
      "361  1\\n00:00:21,688 --> 00:00:24,692\\n<i><font col...  \n",
      "362  1\\n00:00:06,000 --> 00:00:12,074\\nAdvertise yo...  \n",
      "363  1\\n00:00:27,240 --> 00:00:30,879\\n<i>Oh, I com...  \n",
      "\n",
      "[364 rows x 2 columns]\n",
      "Общая информация:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 364 entries, 0 to 363\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   movie      364 non-null    object\n",
      " 1   subtitles  364 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 5.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 5 строк:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>subtitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Crown, The S01E01 - Wolferton Splash.en</td>\n",
       "      <td>1\\n00:00:59,400 --&gt; 00:01:03,960\\nIn seeking h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Suits.Episode 1- Denial</td>\n",
       "      <td>1\\n00:00:07,298 --&gt; 00:00:09,332\\nYou're the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crazy4TV.com - Suits.S06E06.720p.BluRay.x265.H...</td>\n",
       "      <td>1\\n00:00:00,877 --&gt; 00:00:02,337\\n(HARVEY READ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suits.S02E08.HDTV.x264-EVOLVE</td>\n",
       "      <td>1\\n00:00:05,640 --&gt; 00:00:07,641\\n[Car horn bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virgin.River.S01E07.INTERNAL.720p.WEB.x264-STRiFE</td>\n",
       "      <td>1\\n00:00:10,468 --&gt; 00:00:13,178\\nAre you sure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               movie  \\\n",
       "0            Crown, The S01E01 - Wolferton Splash.en   \n",
       "1                            Suits.Episode 1- Denial   \n",
       "2  Crazy4TV.com - Suits.S06E06.720p.BluRay.x265.H...   \n",
       "3                      Suits.S02E08.HDTV.x264-EVOLVE   \n",
       "4  Virgin.River.S01E07.INTERNAL.720p.WEB.x264-STRiFE   \n",
       "\n",
       "                                           subtitles  \n",
       "0  1\\n00:00:59,400 --> 00:01:03,960\\nIn seeking h...  \n",
       "1  1\\n00:00:07,298 --> 00:00:09,332\\nYou're the m...  \n",
       "2  1\\n00:00:00,877 --> 00:00:02,337\\n(HARVEY READ...  \n",
       "3  1\\n00:00:05,640 --> 00:00:07,641\\n[Car horn bl...  \n",
       "4  1\\n00:00:10,468 --> 00:00:13,178\\nAre you sure...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных значений в каждом столбце:\n",
      "Столбец: movie\n",
      "Количество уникальных значений: 279\n",
      "--------------------\n",
      "Столбец: subtitles\n",
      "Количество уникальных значений: 278\n",
      "--------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dictionaries'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         word level\n",
      "0        bank    A1\n",
      "1         buy    A1\n",
      "2      course    A1\n",
      "3         bar    A1\n",
      "4          by    A1\n",
      "...       ...   ...\n",
      "11077     The    C1\n",
      "11078  Oxford    C1\n",
      "11079      by    C1\n",
      "11080    CEFR    C1\n",
      "11081   level    C1\n",
      "\n",
      "[11082 rows x 2 columns]\n",
      "Общая информация:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11082 entries, 0 to 11081\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   word    11082 non-null  object\n",
      " 1   level   11082 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 173.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 5 строк:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buy</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>course</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bar</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>by</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word level\n",
       "0    bank    A1\n",
       "1     buy    A1\n",
       "2  course    A1\n",
       "3     bar    A1\n",
       "4      by    A1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных значений в каждом столбце:\n",
      "Столбец: word\n",
      "Количество уникальных значений: 5032\n",
      "--------------------\n",
      "Столбец: level\n",
      "Количество уникальных значений: 5\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# посмотрим общую информацию о датафреймах\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    display(name)\n",
    "    get_data_info(df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c5dcb",
   "metadata": {},
   "source": [
    "Дополнительно посмотрим отчеты sweetviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим отчет для df_xls\n",
    "report_xls = sv.analyze(df_xls)\n",
    "report_xls.show_html('sweetviz_report_xls.html')\n",
    "\n",
    "# создадим отчет для df_subtitles\n",
    "report_subtitles = sv.analyze(df_subtitles)\n",
    "report_subtitles.show_html('sweetviz_report_subtitles.html')\n",
    "\n",
    "# создадим отчета для df_dictionaries\n",
    "report_dictionaries = sv.analyze(df_dictionaries)\n",
    "report_dictionaries.show_html('sweetviz_report_dictionaries.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c772046",
   "metadata": {},
   "source": [
    "**Вывод:** \n",
    "    \n",
    "**df_xls:**<br>\n",
    "Пропущенных значений нет.<br>\n",
    "В столбце Movie есть дубликаты.<br>\n",
    "В столбце level есть двойные значения. От них нужно избавиться.<br>\n",
    "\n",
    "**df_subtitles:**<br> \n",
    "Пропущенных значений нет.<br>\n",
    "Имеются дубликаты.<br>\n",
    "Необходима предобработка текста в субтитрах.<br> \n",
    "\n",
    "**df_dictionaries:**<br> \n",
    "Пропущенных значений нет.<br>\n",
    "Имеются дубликаты в столбце word.<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5cfbec",
   "metadata": {},
   "source": [
    "## Проведем предобработку данных ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba97edb",
   "metadata": {},
   "source": [
    "### Проведем предобработку df_xls ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27bd853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# исправим названия столбцов \n",
    "df_xls = df_xls.rename(columns={'Movie': 'movie', 'Level': 'level'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c5e02c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                 movie       level\n",
      "38  38          Powder(1995)          B1\n",
      "43  43      Inside_out(2015)          B1\n",
      "44  44      Inside_out(2015)          B1\n",
      "68  68          Powder(1995)          B1\n",
      "75  75  The_blind_side(2009)          B2\n",
      "83  83    The_terminal(2004)          B1\n",
      "84  84  The_blind_side(2009)          B1\n",
      "99  99    The_terminal(2004)  A2/A2+, B1\n"
     ]
    }
   ],
   "source": [
    "# проверим дубликаты\n",
    "duplicated_movies = df_xls[df_xls.duplicated('movie', keep=False)]\n",
    "print(duplicated_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9b94c",
   "metadata": {},
   "source": [
    "Некоторые фильмы дублируются, но имеют разные уровни. Сохраним более высокий уровень. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8192db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B2            101\n",
       "B1             55\n",
       "C1             40\n",
       "A2/A2+         26\n",
       "B1, B2          8\n",
       "A2              6\n",
       "A2/A2+, B1      5\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xls['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21a0c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим дубликаты \n",
    "\n",
    "# преобразуем уровни в числовые значения\n",
    "level_mapping = {\"A1\": 1, \"A2\": 2, \"A2/A2+\": 2, \"A2/A2+, B1\": 3, \"B1\": 3, \"B1, B2\": 3, \"B2\": 4, \"C1\": 5, \"C2\": 6}\n",
    "df_xls['level'] = df_xls['level'].map(level_mapping)\n",
    "\n",
    "# отсортируем по убыванию) и оставим только первое появление каждого фильма\n",
    "df_xls = df_xls.sort_values('level', ascending=False).drop_duplicates('movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91db1fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, movie, level]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# повторно проверим дубликаты\n",
    "duplicated_movies = df_xls[df_xls.duplicated('movie', keep=False)]\n",
    "print(duplicated_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbfec324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим, какие значения теперь есть в level\n",
    "df_xls['level'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14a063a",
   "metadata": {},
   "source": [
    "Нам нужно очистить названия фильмов. Уберем знаки препинания и пробелы. Удалять цифры не будем, так как они могут быть важны, например, если это указание на серию сериала или часть фильма. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a981712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для удаления знаков препинания и пробелов из названий фильмов\n",
    "def simplify_title(title):\n",
    "    # Удаляем все символы, кроме букв и цифр\n",
    "    title = re.sub(r'[^a-zA-Z0-9]', '', title)\n",
    "    # Преобразуем все к нижнему регистру\n",
    "    title = title.lower()\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a559d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим функцию \n",
    "df_xls['movie'] = df_xls['movie'].apply(simplify_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b29484b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id   movie                                           level\n",
       "0    10cloverfieldlane2016                           3        1\n",
       "167  suitsepisode5toetotoe                           4        1\n",
       "155  sommintothebottle20151080pblurayx265rarbgensrt  4        1\n",
       "156  suitsepisode1denial                             4        1\n",
       "157  suitsepisode10faith                             4        1\n",
       "                                                             ..\n",
       "86   thecabininthewoods2012                          2        1\n",
       "87   thefaultinourstars2014                          3        1\n",
       "88   thegraduate1967                                 3        1\n",
       "89   thehangover2009                                 4        1\n",
       "240  thegrinch                                       3        1\n",
       "Length: 237, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# проверим результат \n",
    "display(df_xls.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4ce6fa6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>211</td>\n",
       "      <td>suitss04e03engsub</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>224</td>\n",
       "      <td>suitss04e16engsub</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>oceanseleven2001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>221</td>\n",
       "      <td>suitss04e13engsub</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>220</td>\n",
       "      <td>suitss04e12engsub</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id              movie  level\n",
       "211  211  suitss04e03engsub      5\n",
       "224  224  suitss04e16engsub      5\n",
       "64    64   oceanseleven2001      5\n",
       "221  221  suitss04e13engsub      5\n",
       "220  220  suitss04e12engsub      5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на финальную версию \n",
    "df_xls.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66284c",
   "metadata": {},
   "source": [
    "Удалим столбец id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bbf05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xls.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f3b79",
   "metadata": {},
   "source": [
    "### Проведем предобраобтку df_subtitles ### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b277e4d",
   "metadata": {},
   "source": [
    "Избавимся от дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7babb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     movie  \\\n",
      "163                            Dredd(2012)   \n",
      "165  The_secret_life_of_Walter_Mitty(2013)   \n",
      "166                            Shrek(2001)   \n",
      "167                         Deadpool(2016)   \n",
      "168               We_are_the_Millers(2013)   \n",
      "..                                     ...   \n",
      "359             The_greatest_showman(2017)   \n",
      "360         Kubo_and_the_two_strings(2016)   \n",
      "361                          Matilda(1996)   \n",
      "362                              Her(2013)   \n",
      "363                          Aladdin(1992)   \n",
      "\n",
      "                                             subtitles  \n",
      "163  1\\n00:00:59,017 --> 00:01:02,103\\nAmerica is a...  \n",
      "165  1\\n00:02:33,080 --> 00:02:34,081\\nHuh?\\n\\n2\\n0...  \n",
      "166  1\\n00:00:01,000 --> 00:00:04,074\\nanoXmous\\nht...  \n",
      "167  1\\n00:00:03,259 --> 00:00:20,645\\n<font color=...  \n",
      "168  1\\n00:00:02,400 --> 00:00:03,731\\n<i>Oh, my Go...  \n",
      "..                                                 ...  \n",
      "359  1\\n00:00:09,877 --> 00:00:13,081\\n♪ Whoa ♪\\n\\n...  \n",
      "360  1\\n00:00:23,240 --> 00:00:26,403\\nIf you must ...  \n",
      "361  1\\n00:00:21,688 --> 00:00:24,692\\n<i><font col...  \n",
      "362  1\\n00:00:06,000 --> 00:00:12,074\\nAdvertise yo...  \n",
      "363  1\\n00:00:27,240 --> 00:00:30,879\\n<i>Oh, I com...  \n",
      "\n",
      "[170 rows x 2 columns]\n",
      "movie        85\n",
      "subtitles    85\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# посмотрим все дублированные строки\n",
    "df_duplicates = df_subtitles[df_subtitles.duplicated(keep=False)]\n",
    "print(df_duplicates)\n",
    "print(df_duplicates.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d44c7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим дубликаты строк\n",
    "df_subtitles.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a751c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим функцию очистки названий к названию фильма\n",
    "df_subtitles['movie'] = df_subtitles['movie'].apply(simplify_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc7bd2d",
   "metadata": {},
   "source": [
    "Очистим текст "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f7c500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для очистки текста \n",
    "\n",
    "def clean_text(text):\n",
    "    # удалим числа и ненужные символы\n",
    "    cleaned_text = re.sub(r\"[^a-z\\s']+\", \" \", text.lower())\n",
    "    # удалим множественные пробелы\n",
    "    cleaned_text = re.sub(' +', ' ', cleaned_text)\n",
    "    # преобразуем строку в список слов\n",
    "    words = cleaned_text.split()\n",
    "    return words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2929f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим функцию к субтитрам\n",
    "df_subtitles['subtitles'] = df_subtitles['subtitles'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dceded",
   "metadata": {},
   "source": [
    "Удалим слова, которые для нас не несут смысловую нагрузку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1358da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим список английских стоп-слов\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4261bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для удаления знаков пунктуации из списка слов\n",
    "def remove_punctuation(word_list):\n",
    "    no_punct = [word for word in word_list if word.isalpha()]\n",
    "    return no_punct\n",
    "\n",
    "# функция для удаления стоп-слов из списка слов\n",
    "def remove_stopwords(word_list):\n",
    "    no_stop_words = [word for word in word_list if word not in stop_words]\n",
    "    return no_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a620bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# приведем все слова к нижнему регистру\n",
    "df_subtitles['subtitles'] = df_subtitles['subtitles'].apply(lambda x: [word.lower() for word in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56d32321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим функции \n",
    "df_subtitles['subtitles'] = df_subtitles['subtitles'].apply(lambda x: remove_stopwords(x))\n",
    "df_subtitles['subtitles'] = df_subtitles['subtitles'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56299542",
   "metadata": {},
   "source": [
    "Проведем лемматизацию слов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff42934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем лемматизатор\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# функция для лемматизации списка слов\n",
    "def lemmatize_words(word_list):\n",
    "    return [lemmatizer.lemmatize(word) for word in word_list]\n",
    "\n",
    "# применим функцию лемматизации к нашим данным\n",
    "df_subtitles['subtitles'] = df_subtitles['subtitles'].apply(lemmatize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "274e3a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 8 0]]\n"
     ]
    }
   ],
   "source": [
    "# cоздадим мешок слов \n",
    "\n",
    "# инициализируем CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# объединим слова в строку\n",
    "df_subtitles['subtitles_str'] = df_subtitles['subtitles'].apply(' '.join)\n",
    "\n",
    "# применим векторизатор к колонке с субтитрами\n",
    "bag_of_words = vectorizer.fit_transform(df_subtitles['subtitles_str'])\n",
    "\n",
    "# преобразуем в numpy array и печатаем результат\n",
    "bow_matrix = bag_of_words.toarray()\n",
    "print(bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6c5c18",
   "metadata": {},
   "source": [
    "Проведем векторизацию текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b7113f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.03307433]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.04324407 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# создадим экземпляр TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# преобразуем лемматизированные тексты в числовые векторы TF-IDF\n",
    "tfidf_vectors = vectorizer.fit_transform(df_subtitles['subtitles'].astype(str))\n",
    "\n",
    "# получим матрицу TF-IDF-векторов\n",
    "tfidf_matrix = tfidf_vectors.toarray()\n",
    "\n",
    "# посмотрим результаты\n",
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a6aa28d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>subtitles_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crownthes01e01wolfertonsplashen</td>\n",
       "      <td>[seeking, british, nationalization, royal, hig...</td>\n",
       "      <td>seeking british nationalization royal highness...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>suitsepisode1denial</td>\n",
       "      <td>[amazing, woman, ever, met, think, rachel, eli...</td>\n",
       "      <td>amazing woman ever met think rachel elizabeth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crazy4tvcomsuitss06e06720pblurayx265hevccrazy4ad</td>\n",
       "      <td>[harvey, reading, sutter, three, year, one, sl...</td>\n",
       "      <td>harvey reading sutter three year one slippery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suitss02e08hdtvx264evolve</td>\n",
       "      <td>[car, horn, blare, late, nope, second, early, ...</td>\n",
       "      <td>car horn blare late nope second early good lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginrivers01e07internal720pwebx264strife</td>\n",
       "      <td>[sure, convince, stay, right, time, go, home, ...</td>\n",
       "      <td>sure convince stay right time go home oh know ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              movie  \\\n",
       "0                   crownthes01e01wolfertonsplashen   \n",
       "1                               suitsepisode1denial   \n",
       "2  crazy4tvcomsuitss06e06720pblurayx265hevccrazy4ad   \n",
       "3                         suitss02e08hdtvx264evolve   \n",
       "4        virginrivers01e07internal720pwebx264strife   \n",
       "\n",
       "                                           subtitles  \\\n",
       "0  [seeking, british, nationalization, royal, hig...   \n",
       "1  [amazing, woman, ever, met, think, rachel, eli...   \n",
       "2  [harvey, reading, sutter, three, year, one, sl...   \n",
       "3  [car, horn, blare, late, nope, second, early, ...   \n",
       "4  [sure, convince, stay, right, time, go, home, ...   \n",
       "\n",
       "                                       subtitles_str  \n",
       "0  seeking british nationalization royal highness...  \n",
       "1  amazing woman ever met think rachel elizabeth ...  \n",
       "2  harvey reading sutter three year one slippery ...  \n",
       "3  car horn blare late nope second early good lea...  \n",
       "4  sure convince stay right time go home oh know ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на финальную версию \n",
    "df_subtitles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1f4e06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>subtitles_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>suitss04e03engsub</td>\n",
       "      <td>[previously, suit, good, working, takeover, lo...</td>\n",
       "      <td>previously suit good working takeover logan lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 movie                                          subtitles  \\\n",
       "144  suitss04e03engsub  [previously, suit, good, working, takeover, lo...   \n",
       "\n",
       "                                         subtitles_str  \n",
       "144  previously suit good working takeover logan lo...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subtitles[df_subtitles['movie'] == 'suitss04e03engsub']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3fda9e",
   "metadata": {},
   "source": [
    "### Проведем предобраобтку df_dictionaries ### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6fd4f",
   "metadata": {},
   "source": [
    "Преобразуем уровни в числовые значения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e99bdf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем уровни в числовые значения\n",
    "level_mapping = {\"A1\": 1, \"A2\": 2, \"A2/A2+\": 2, \"A2/A2+, B1\": 3, \"B1\": 3, \"B1, B2\": 3, \"B2\": 4, \"C1\": 5, \"C2\": 6}\n",
    "df_dictionaries[\"level\"] = df_dictionaries[\"level\"].map(level_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b36b3",
   "metadata": {},
   "source": [
    "Преобразуем столбец word к нижнему регистру "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d7e7388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем столбец \"word\" к нижнему регистру\n",
    "df_dictionaries[\"word\"] = df_dictionaries[\"word\"].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d85c033",
   "metadata": {},
   "source": [
    "Проверим дубликаты "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "200dedf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         word  level\n",
      "0        bank      1\n",
      "1         buy      1\n",
      "2      course      1\n",
      "4          by      1\n",
      "5      cousin      1\n",
      "...       ...    ...\n",
      "11077     the      5\n",
      "11078  oxford      5\n",
      "11079      by      5\n",
      "11080    cefr      5\n",
      "11081   level      5\n",
      "\n",
      "[8717 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "duplicates = df_dictionaries[df_dictionaries.duplicated(keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68009f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word      level\n",
       "number    1        67\n",
       "oxford    5        27\n",
       "          4        25\n",
       "          2        18\n",
       "the       4        16\n",
       "                   ..\n",
       "indicate  3         1\n",
       "indirect  2         1\n",
       "          3         1\n",
       "indoor    2         1\n",
       "label     3         1\n",
       "Length: 6472, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dictionaries.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "beab1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим дубликаты\n",
    "df_dictionaries = df_dictionaries.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8401f930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word         level\n",
       "a            2        1\n",
       "precede      4        1\n",
       "prediction   2        1\n",
       "predictable  4        1\n",
       "predict      2        1\n",
       "                     ..\n",
       "existence    4        1\n",
       "exist        2        1\n",
       "exile        5        1\n",
       "exhibition   3        1\n",
       "zone         4        1\n",
       "Length: 6472, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dictionaries.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "370bf4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8882</th>\n",
       "      <td>troubled</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7701</th>\n",
       "      <td>accountable</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>see</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>ingredient</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>prisoner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  level\n",
       "8882     troubled      5\n",
       "7701  accountable      5\n",
       "622           see      1\n",
       "2100   ingredient      3\n",
       "2524     prisoner      3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на финальную версию \n",
    "df_dictionaries.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6500f41",
   "metadata": {},
   "source": [
    "Преобразуем df_dictionaries в словарь "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "745bf58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем df_dictionaries в словарь\n",
    "word_levels = df_dictionaries.set_index('word')['level'].to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d9d009",
   "metadata": {},
   "source": [
    "### Объединим таблицы ### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9385fe6e",
   "metadata": {},
   "source": [
    "Объединим df_xls и df_subtitles по столбцу movie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e0203f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>subtitles_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>suitss04e03engsub</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[previously, suit, good, working, takeover, lo...</td>\n",
       "      <td>previously suit good working takeover logan lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>suitss04e16engsub</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[jeff, jessica, right, either, need, going, wo...</td>\n",
       "      <td>jeff jessica right either need going work effe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oceanseleven2001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[guard, one, con, escort, open, gate, one, gat...</td>\n",
       "      <td>guard one con escort open gate one gate open m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suitss04e13engsub</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[got, name, wall, want, respect, come, meaning...</td>\n",
       "      <td>got name wall want respect come meaning want o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suitss04e12engsub</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[professor, gerard, came, ask, favor, brought,...</td>\n",
       "      <td>professor gerard came ask favor brought know t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               movie  level  \\\n",
       "0  suitss04e03engsub    5.0   \n",
       "1  suitss04e16engsub    5.0   \n",
       "2   oceanseleven2001    5.0   \n",
       "3  suitss04e13engsub    5.0   \n",
       "4  suitss04e12engsub    5.0   \n",
       "\n",
       "                                           subtitles  \\\n",
       "0  [previously, suit, good, working, takeover, lo...   \n",
       "1  [jeff, jessica, right, either, need, going, wo...   \n",
       "2  [guard, one, con, escort, open, gate, one, gat...   \n",
       "3  [got, name, wall, want, respect, come, meaning...   \n",
       "4  [professor, gerard, came, ask, favor, brought,...   \n",
       "\n",
       "                                       subtitles_str  \n",
       "0  previously suit good working takeover logan lo...  \n",
       "1  jeff jessica right either need going work effe...  \n",
       "2  guard one con escort open gate one gate open m...  \n",
       "3  got name wall want respect come meaning want o...  \n",
       "4  professor gerard came ask favor brought know t...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# объединим таблицы df_xls и df_subtitles по столбцу 'movie'\n",
    "df_merged = df_xls.merge(df_subtitles, on='movie', how='outer')\n",
    "\n",
    "display(df_merged.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794a6f1",
   "metadata": {},
   "source": [
    "Посмотрим на результат объединения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a12e9090",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 movie  level  \\\n",
      "0                                    suitss04e03engsub    5.0   \n",
      "1                                    suitss04e16engsub    5.0   \n",
      "2                                     oceanseleven2001    5.0   \n",
      "3                                    suitss04e13engsub    5.0   \n",
      "4                                    suitss04e12engsub    5.0   \n",
      "..                                                 ...    ...   \n",
      "281                                     theghostwriter    NaN   \n",
      "282             harrypotterandthephilosophersstone2001    NaN   \n",
      "283                                             casper    NaN   \n",
      "284                                  prideandprejudice    NaN   \n",
      "285  brenbrownthecalltocourage2019720nf720pddp51x26...    NaN   \n",
      "\n",
      "                                             subtitles  \\\n",
      "0    [previously, suit, good, working, takeover, lo...   \n",
      "1    [jeff, jessica, right, either, need, going, wo...   \n",
      "2    [guard, one, con, escort, open, gate, one, gat...   \n",
      "3    [got, name, wall, want, respect, come, meaning...   \n",
      "4    [professor, gerard, came, ask, favor, brought,...   \n",
      "..                                                 ...   \n",
      "281  [music, music, music, music, music, music, app...   \n",
      "282  [known, would, professor, mcgonagall, good, ev...   \n",
      "283  [music, music, okay, one, picture, history, af...   \n",
      "284  [music, music, um, music, music, music, lydia,...   \n",
      "285  [presenter, spent, year, studying, courage, vu...   \n",
      "\n",
      "                                         subtitles_str  \n",
      "0    previously suit good working takeover logan lo...  \n",
      "1    jeff jessica right either need going work effe...  \n",
      "2    guard one con escort open gate one gate open m...  \n",
      "3    got name wall want respect come meaning want o...  \n",
      "4    professor gerard came ask favor brought know t...  \n",
      "..                                                 ...  \n",
      "281  music music music music music music applause h...  \n",
      "282  known would professor mcgonagall good evening ...  \n",
      "283  music music okay one picture history afraid mu...  \n",
      "284  music music um music music music lydia kitty m...  \n",
      "285  presenter spent year studying courage vulnerab...  \n",
      "\n",
      "[286 rows x 4 columns]\n",
      "Общая информация:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 286 entries, 0 to 285\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   movie          286 non-null    object \n",
      " 1   level          238 non-null    float64\n",
      " 2   subtitles      279 non-null    object \n",
      " 3   subtitles_str  279 non-null    object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 11.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 5 строк:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>subtitles_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>suitss04e03engsub</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[previously, suit, good, working, takeover, lo...</td>\n",
       "      <td>previously suit good working takeover logan lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>suitss04e16engsub</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[jeff, jessica, right, either, need, going, wo...</td>\n",
       "      <td>jeff jessica right either need going work effe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oceanseleven2001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[guard, one, con, escort, open, gate, one, gat...</td>\n",
       "      <td>guard one con escort open gate one gate open m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suitss04e13engsub</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[got, name, wall, want, respect, come, meaning...</td>\n",
       "      <td>got name wall want respect come meaning want o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suitss04e12engsub</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[professor, gerard, came, ask, favor, brought,...</td>\n",
       "      <td>professor gerard came ask favor brought know t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               movie  level  \\\n",
       "0  suitss04e03engsub    5.0   \n",
       "1  suitss04e16engsub    5.0   \n",
       "2   oceanseleven2001    5.0   \n",
       "3  suitss04e13engsub    5.0   \n",
       "4  suitss04e12engsub    5.0   \n",
       "\n",
       "                                           subtitles  \\\n",
       "0  [previously, suit, good, working, takeover, lo...   \n",
       "1  [jeff, jessica, right, either, need, going, wo...   \n",
       "2  [guard, one, con, escort, open, gate, one, gat...   \n",
       "3  [got, name, wall, want, respect, come, meaning...   \n",
       "4  [professor, gerard, came, ask, favor, brought,...   \n",
       "\n",
       "                                       subtitles_str  \n",
       "0  previously suit good working takeover logan lo...  \n",
       "1  jeff jessica right either need going work effe...  \n",
       "2  guard one con escort open gate one gate open m...  \n",
       "3  got name wall want respect come meaning want o...  \n",
       "4  professor gerard came ask favor brought know t...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных значений в каждом столбце:\n",
      "Столбец: movie\n",
      "Количество уникальных значений: 285\n",
      "--------------------\n",
      "Столбец: level\n",
      "Количество уникальных значений: 4\n",
      "--------------------\n",
      "Столбец: subtitles_str\n",
      "Количество уникальных значений: 278\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "get_data_info(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88b97702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    101\n",
       "3.0     64\n",
       "5.0     40\n",
       "2.0     33\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['level'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52588a06",
   "metadata": {},
   "source": [
    "***Вывод:*** \n",
    "    В получившейся таблице есть пропуски в level и subtitles. \n",
    "    Уровень языка мы сможем вычислить, сопоставив слова в субтитрах со словарем. \n",
    "    Есть пропуски в subtitles. В идеале можно было бы найти и скачать эти субтитры, но в силу нехватки времени на выполнение проекта удалим эти строки. \n",
    "    Итого у нас есть 238 записей для обучения модели (train) и 48 записей для тестирования модели (test). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666fac07",
   "metadata": {},
   "source": [
    "Разберемся с пропущенными значениями "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e793c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим строки с пропущенными значениями\n",
    "df_cleaned = df_merged.dropna(subset=['subtitles', 'subtitles_str'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745dc0a9",
   "metadata": {},
   "source": [
    "## Обучим модель ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba51f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделим данные на обучающую и тестовую выборки\n",
    "train = df_cleaned[df_cleaned['level'].notna()]\n",
    "test = df_cleaned[df_cleaned['level'].isna()]\n",
    "\n",
    "# разделим данные и train и testabs\n",
    "x_train = train['subtitles_str']\n",
    "y_train = train['level']\n",
    "x_test = test['subtitles_str']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19110eaa",
   "metadata": {},
   "source": [
    "Применим мешок слов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6367c4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим мешка слов\n",
    "vectorizer = CountVectorizer()\n",
    "x_train_counts = vectorizer.fit_transform(x_train)\n",
    "x_test_counts = vectorizer.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d47b0",
   "metadata": {},
   "source": [
    "Применим tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91f0b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим TF-IDF\n",
    "tfidf_transformer = TfidfVectorizer()\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(x_train)\n",
    "x_test_tfidf = tfidf_transformer.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c4876",
   "metadata": {},
   "source": [
    "Сбалансируем классы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d08492f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим балансировку классов \n",
    "ros = RandomOverSampler(random_state=0)\n",
    "x_resampled, y_resampled = ros.fit_resample(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3cb02c",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67f1f65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры логистической регрессии:  {'C': 100, 'penalty': 'l2'}\n",
      "Точность логистической регрессии на кросс-валидации:  0.860939060939061\n"
     ]
    }
   ],
   "source": [
    "# обучим модель логистической регрессии с подбором гиперпараметров и кросс-валидацией\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "grid_search_lr = GridSearchCV(estimator=logistic_regression, param_grid=param_grid_lr, cv=5, scoring='accuracy')\n",
    "grid_search_lr.fit(x_resampled, y_resampled)\n",
    "\n",
    "best_model_lr = grid_search_lr.best_estimator_\n",
    "\n",
    "# оценка качества модели на кросс-валидации\n",
    "cv_results_lr = cross_val_score(best_model_lr, x_resampled, y_resampled, cv=5, scoring='accuracy')\n",
    "\n",
    "print('Лучшие параметры логистической регрессии: ', grid_search_lr.best_params_)\n",
    "print('Точность логистической регрессии на кросс-валидации: ', cv_results_lr.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e34fce",
   "metadata": {},
   "source": [
    "Обучим модель градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c27bbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры градиентного бустинга:  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Точность градиентного бустинга на кросс-валидации:  0.8789876789876789\n"
     ]
    }
   ],
   "source": [
    "# обучим модель градиентного бустинга с подбором гиперпараметров и кросс-валидацией\n",
    "gradient_boosting = GradientBoostingClassifier()\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "grid_search_gb = GridSearchCV(estimator=gradient_boosting, param_grid=param_grid_gb, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_gb.fit(x_resampled, y_resampled)\n",
    "\n",
    "best_model_gb = grid_search_gb.best_estimator_\n",
    "\n",
    "# оценим качество модели на кросс-валидации\n",
    "cv_results_gb = cross_val_score(best_model_gb, x_resampled, y_resampled, cv=5, scoring='accuracy')\n",
    "\n",
    "print('Лучшие параметры градиентного бустинга: ', grid_search_gb.best_params_)\n",
    "print('Точность градиентного бустинга на кросс-валидации: ', cv_results_gb.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e111e7",
   "metadata": {},
   "source": [
    "***Вывод:*** \n",
    "\n",
    "Лучшие параметры логистической регрессии:  {'C': 100, 'penalty': 'l2'}\n",
    "Точность логистической регрессии на кросс-валидации:  0.860939060939061\n",
    "\n",
    "Лучшие параметры градиентного бустинга:  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
    "Точность градиентного бустинга на кросс-валидации:  0.8789876789876789\n",
    "\n",
    "Модель градиентного бустинга показала немного более высокий результат. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b928fa",
   "metadata": {},
   "source": [
    "***Итоговый вывод:*** \n",
    "Мы построили две модели для предсказания уровня сложности фильма по его субтитрам: модель логистической регрессии и модель градиентного бустинга.<br> \n",
    "\n",
    "Лучшие параметры логистической регрессии:  {'C': 100, 'penalty': 'l2'}\n",
    "Точность логистической регрессии на кросс-валидации:  0.860939060939061\n",
    "\n",
    "Лучшие параметры градиентного бустинга:  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
    "Точность градиентного бустинга на кросс-валидации:  0.8789876789876789\n",
    "\n",
    "Более высокий результат показала модель градиентного бустинга со следующими гиперпараметрами: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}. \n",
    "Точность градиентного бустинга на кросс-валидации составила примерно 0.879, что означает, что модель с лучшими найденными параметрами достигает примерно 87.9% точности в предсказании уровня английского языка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5f233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
